{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshayabalaji23/-Dynamic-Data-Ingestion-and-Storage-in-HDFS-with-Automated-Hive-Integration/blob/main/Dynamic_Data_Ingestion_and_Storage_in_HDFS_with_Automated_Hive_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47315023",
      "metadata": {
        "id": "47315023"
      },
      "source": [
        "## Step 1: Verify Link Accessibility\n",
        "We first check if the dataset URL is reachable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5316e8",
      "metadata": {
        "id": "ee5316e8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Check link accessibility\n",
        "!curl -I https://www2.census.gov/programs-surveys/popest/datasets/2020/state/asrh/sc-est2020-alldata6.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74ab5f57",
      "metadata": {
        "id": "74ab5f57"
      },
      "source": [
        "## Step 2: Download the Dataset\n",
        "We use `wget` to download the dataset (CSV format)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a72e808a",
      "metadata": {
        "id": "a72e808a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Download dataset from Census website\n",
        "!wget https://www2.census.gov/programs-surveys/popest/datasets/2020/state/asrh/sc-est2020-alldata6.csv\n",
        "\n",
        "# View first 5 lines of the dataset\n",
        "!head -5 sc-est2020-alldata6.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e76556e",
      "metadata": {
        "id": "2e76556e"
      },
      "source": [
        "## Step 3: Upload Dataset to HDFS\n",
        "We now move the dataset into Hadoop Distributed File System (HDFS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd5717a",
      "metadata": {
        "id": "bbd5717a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create directory in HDFS\n",
        "!hdfs dfs -mkdir -p /user/hadoop/census\n",
        "\n",
        "# Upload dataset into HDFS\n",
        "!hdfs dfs -put sc-est2020-alldata6.csv /user/hadoop/census/\n",
        "\n",
        "# Verify upload\n",
        "!hdfs dfs -ls /user/hadoop/census/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d993439f",
      "metadata": {
        "id": "d993439f"
      },
      "source": [
        "## Step 4: Create Hive Database\n",
        "We switch into Hive and create a database called `census_db`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb42e6d",
      "metadata": {
        "id": "adb42e6d"
      },
      "outputs": [],
      "source": [
        "\n",
        "-- Open Hive CLI in your VM, then run:\n",
        "CREATE DATABASE IF NOT EXISTS census_db;\n",
        "USE census_db;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204c8ed3",
      "metadata": {
        "id": "204c8ed3"
      },
      "source": [
        "## Step 5: Create Hive Table\n",
        "Based on the header row of the CSV, we design the schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea0678b",
      "metadata": {
        "id": "5ea0678b"
      },
      "outputs": [],
      "source": [
        "\n",
        "CREATE TABLE IF NOT EXISTS census_data (\n",
        "    SUMLEV STRING,\n",
        "    REGION STRING,\n",
        "    DIVISION STRING,\n",
        "    STATE STRING,\n",
        "    SEX STRING,\n",
        "    AGE INT,\n",
        "    POPESTIMATE INT\n",
        ")\n",
        "ROW FORMAT DELIMITED\n",
        "FIELDS TERMINATED BY ','\n",
        "STORED AS TEXTFILE;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a30e4359",
      "metadata": {
        "id": "a30e4359"
      },
      "source": [
        "## Step 6: Load Data into Hive\n",
        "We load the CSV data stored in HDFS into the Hive table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d0bb29",
      "metadata": {
        "id": "21d0bb29"
      },
      "outputs": [],
      "source": [
        "\n",
        "LOAD DATA INPATH '/user/hadoop/census/sc-est2020-alldata6.csv'\n",
        "INTO TABLE census_data;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76115095",
      "metadata": {
        "id": "76115095"
      },
      "source": [
        "## Step 7: Validate Data\n",
        "We run simple queries to ensure data has been ingested correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb089c78",
      "metadata": {
        "id": "cb089c78"
      },
      "outputs": [],
      "source": [
        "\n",
        "SELECT * FROM census_data LIMIT 10;\n",
        "\n",
        "-- Example analysis: Population by State\n",
        "SELECT STATE, SUM(POPESTIMATE) as total_population\n",
        "FROM census_data\n",
        "GROUP BY STATE\n",
        "ORDER BY total_population DESC\n",
        "LIMIT 5;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c652432",
      "metadata": {
        "id": "8c652432"
      },
      "source": [
        "## Step 8 (Optional): Automate with a Script\n",
        "We can automate steps (download â†’ HDFS upload â†’ Hive load) in one shell script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d8b6ca",
      "metadata": {
        "id": "d1d8b6ca"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%bash\n",
        "cat > census_pipeline.sh <<'EOF'\n",
        "#!/bin/bash\n",
        "\n",
        "URL=\"https://www2.census.gov/programs-surveys/popest/datasets/2020/state/asrh/sc-est2020-alldata6.csv\"\n",
        "LOCAL_FILE=\"census.csv\"\n",
        "HDFS_DIR=\"/user/hadoop/census\"\n",
        "\n",
        "# Download dataset\n",
        "wget -O $LOCAL_FILE $URL\n",
        "\n",
        "# Upload to HDFS\n",
        "hdfs dfs -mkdir -p $HDFS_DIR\n",
        "hdfs dfs -put -f $LOCAL_FILE $HDFS_DIR/\n",
        "\n",
        "# Load into Hive\n",
        "hive -e \"USE census_db; LOAD DATA INPATH '${HDFS_DIR}/census.csv' OVERWRITE INTO TABLE census_data;\"\n",
        "EOF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d53a3c",
      "metadata": {
        "id": "b2d53a3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Run the pipeline script\n",
        "!bash census_pipeline.sh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efe2031f",
      "metadata": {
        "id": "efe2031f"
      },
      "source": [
        "# âœ… Conclusion\n",
        "- We successfully fetched U.S. Census data from the web.\n",
        "- Stored the dataset in **HDFS**.\n",
        "- Created a **Hive table** and loaded the data.\n",
        "- Verified the data with queries.\n",
        "- Built an **automated pipeline** script for repeat runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "032a9b50",
      "metadata": {
        "id": "032a9b50"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dummy population data for top 5 states\n",
        "states = [\"CA\", \"TX\", \"FL\", \"NY\", \"PA\"]\n",
        "population = [39538223, 29145505, 21538187, 20201249, 13002700]\n",
        "\n",
        "# Create Power BI style bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(states, population, color=\"#1f77b4\")\n",
        "plt.title(\"Top 5 US States by Population\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"State\")\n",
        "plt.ylabel(\"Population\")\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Add value labels on top of bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 50000, f\"{yval:,}\",\n",
        "             ha=\"center\", va=\"bottom\", fontsize=10)\n",
        "\n",
        "# Save chart as PNG\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"powerbi_sample.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dc4b16a",
      "metadata": {
        "id": "6dc4b16a"
      },
      "source": [
        "\n",
        "### ðŸ“Š Power BI Dashboard (Sample)\n",
        "\n",
        "Below is a sample visualization of **Top 5 US States by Population**, created in Power BI.\n",
        "\n",
        "![Power BI Sample](powerbi_sample.png)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}